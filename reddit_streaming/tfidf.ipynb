{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b3712-90b0-4226-9816-bdc6e42974c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61df7e0f-69cc-44a2-82e8-7843a89ceac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.ml import Pipeline\n",
    "import os\n",
    "import uuid\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    DoubleType\n",
    ")\n",
    "from pyspark.sql.functions import col, window, collect_list, from_unixtime, concat_ws, explode,udf, array, lit, struct, row_number\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5217336-35d8-47d6-9096-fdf43824976e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9730a69b-8804-48f4-ace7-c677841046eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/12 13:26:20 WARN Utils: Your hostname, Exporo-MBP-219.local resolves to a loopback address: 127.0.0.1; using 10.10.5.83 instead (on interface en0)\n",
      "24/06/12 13:26:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/12 13:26:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/12 13:26:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Reddit TF-IDF Processing\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6649e0-d56e-4ad3-9ccf-c3c9be4bcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"data/raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7411f821-e66b-4b6a-8c68-a8ccca8f0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"data/raw/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3e3811-1a32-458f-926e-1766bd92dc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "|     id|            author|  created_utc|score| parent_id|subreddit|           permalink|                text|          timestamp|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a378f4b-7fc2-41ac-b78c-2c97d0ab98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04aa06c-e433-4fe8-8b43-6d23be649fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CountVectorizer to get term frequency\n",
    "cv = CountVectorizer(\n",
    "    inputCol=\"words\", outputCol=\"rawFeatures\", vocabSize=1000, minDF=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99091ea-5eba-4808-9b1c-8a8976cf4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IDF to get TF-IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fa14637-669b-4447-b43a-4239fb5fca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49b464c-f944-4b5b-b6ae-baa285f5eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply windowing\n",
    "windowed_df = df.groupBy(window(col(\"timestamp\"), \"60 seconds\", \"5 seconds\")).agg(\n",
    "    collect_list(\"text\").alias(\"texts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e96c1e7-fcd3-4e3c-9d73-32eb0c1d2b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n",
      "[Stage 3:=======================>                                 (26 + 8) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=33140Kb max_used=33177Kb free=97931Kb\n",
      " bounds [0x0000000104a64000, 0x0000000106af4000, 0x000000010ca64000]\n",
      " total_blobs=13152 nmethods=12163 adapters=899\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>  (61 + 3) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              window|               texts|\n",
      "+--------------------+--------------------+\n",
      "|{2024-06-03 21:11...|            [, , , ]|\n",
      "|{2024-06-03 21:11...|            [, , , ]|\n",
      "|{2024-06-03 21:12...|            [, , , ]|\n",
      "|{2024-06-03 21:12...|            [, , , ]|\n",
      "|{2024-06-03 21:17...|[As someone with ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "windowed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2784700-8d1a-458b-9457-560439a2bd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row = windowed_df.collect()[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d30e66-7791-47dc-a97f-9ec459fee436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(window=Row(start=datetime.datetime(2024, 6, 3, 21, 20, 45), end=datetime.datetime(2024, 6, 3, 21, 21, 45)), texts=['Maybe AI can finally explain exactly what “woke” is supposed to mean, since the people using it constantly have so far been unable to.', 'Maybe AI can finally explain exactly what “woke” is supposed to mean, since the people using it constantly have so far been unable to.', 'Maybe AI can finally explain exactly what “woke” is supposed to mean, since the people using it constantly have so far been unable to.', 'Maybe AI can finally explain exactly what “woke” is supposed to mean, since the people using it constantly have so far been unable to.', 'It is already my dude', 'It is already my dude', 'It is already my dude', 'It is already my dude'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0fd672-8742-47a6-8e2a-e336b7589146",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_start, window_end = row[\"window\"][\"start\"], row[\"window\"][\"end\"]\n",
    "texts = row[\"texts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ca0d9c7-a5c1-4197-82c8-e58649385be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = spark.createDataFrame([(text,) for text in texts], [\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850b8291-960d-49ab-973f-0e90a711cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(texts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "959386d3-80fe-4836-92a0-d25a8feb166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = model.transform(texts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e699453b-e9fc-4e36-8a92-4e7275ef21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.stages[1].vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a244645-3b03-4c44-9fe5-33e95fa2c68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'supposed',\n",
       " 'constantly',\n",
       " 'explain',\n",
       " 'the',\n",
       " 'been',\n",
       " 'people',\n",
       " 'since',\n",
       " 'mean,',\n",
       " 'unable',\n",
       " 'far',\n",
       " 'dude',\n",
       " '“woke”',\n",
       " 'can',\n",
       " 'to',\n",
       " 'using',\n",
       " 'finally',\n",
       " 'have',\n",
       " 'to.',\n",
       " 'my',\n",
       " 'maybe',\n",
       " 'exactly',\n",
       " 'already',\n",
       " 'what',\n",
       " 'ai',\n",
       " 'so']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e92a8ebd-0bfb-43e8-b6d5-5b3a1621a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_words(features):\n",
    "    top_indices = features.indices\n",
    "    top_values = features.values\n",
    "    top_words = [(vocab[i], v) for i, v in zip(top_indices, top_values)]\n",
    "    top_words = sorted(top_words, key=lambda x: x[1], reverse=True)[:10]\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5bdacc2-058f-4545-af40-f202fb9958cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_words = (\n",
    "    tfidf_df.select(\"features\")\n",
    "    .rdd.flatMap(lambda row: extract_top_words(row[\"features\"]))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cc18144-0160-4cd6-909d-7747184b19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supposed', 0.5877866649021191),\n",
       " ('constantly', 0.5877866649021191),\n",
       " ('explain', 0.5877866649021191),\n",
       " ('the', 0.5877866649021191),\n",
       " ('been', 0.5877866649021191),\n",
       " ('people', 0.5877866649021191),\n",
       " ('since', 0.5877866649021191),\n",
       " ('mean,', 0.5877866649021191),\n",
       " ('unable', 0.5877866649021191),\n",
       " ('far', 0.5877866649021191),\n",
       " ('supposed', 0.5877866649021191),\n",
       " ('constantly', 0.5877866649021191),\n",
       " ('explain', 0.5877866649021191),\n",
       " ('the', 0.5877866649021191),\n",
       " ('been', 0.5877866649021191),\n",
       " ('people', 0.5877866649021191),\n",
       " ('since', 0.5877866649021191),\n",
       " ('mean,', 0.5877866649021191),\n",
       " ('unable', 0.5877866649021191),\n",
       " ('far', 0.5877866649021191),\n",
       " ('supposed', 0.5877866649021191),\n",
       " ('constantly', 0.5877866649021191),\n",
       " ('explain', 0.5877866649021191),\n",
       " ('the', 0.5877866649021191),\n",
       " ('been', 0.5877866649021191),\n",
       " ('people', 0.5877866649021191),\n",
       " ('since', 0.5877866649021191),\n",
       " ('mean,', 0.5877866649021191),\n",
       " ('unable', 0.5877866649021191),\n",
       " ('far', 0.5877866649021191),\n",
       " ('supposed', 0.5877866649021191),\n",
       " ('constantly', 0.5877866649021191),\n",
       " ('explain', 0.5877866649021191),\n",
       " ('the', 0.5877866649021191),\n",
       " ('been', 0.5877866649021191),\n",
       " ('people', 0.5877866649021191),\n",
       " ('since', 0.5877866649021191),\n",
       " ('mean,', 0.5877866649021191),\n",
       " ('unable', 0.5877866649021191),\n",
       " ('far', 0.5877866649021191),\n",
       " ('dude', 0.5877866649021191),\n",
       " ('my', 0.5877866649021191),\n",
       " ('already', 0.5877866649021191),\n",
       " ('it', 0.0),\n",
       " ('is', 0.0),\n",
       " ('dude', 0.5877866649021191),\n",
       " ('my', 0.5877866649021191),\n",
       " ('already', 0.5877866649021191),\n",
       " ('it', 0.0),\n",
       " ('is', 0.0),\n",
       " ('dude', 0.5877866649021191),\n",
       " ('my', 0.5877866649021191),\n",
       " ('already', 0.5877866649021191),\n",
       " ('it', 0.0),\n",
       " ('is', 0.0),\n",
       " ('dude', 0.5877866649021191),\n",
       " ('my', 0.5877866649021191),\n",
       " ('already', 0.5877866649021191),\n",
       " ('it', 0.0),\n",
       " ('is', 0.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d43d80-53ab-4640-9d45-6bb735e366f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        return v.toArray().tolist()\n",
    "\n",
    "to_array_udf = udf(to_array, ArrayType(DoubleType()))\n",
    "tfidf_df = tfidf_df.withColumn(\"tfidf_values\", to_array_udf(col(\"features\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5821ef34-0716-471e-a607-d18b32ed918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|         rawFeatures|            features|        tfidf_values|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Maybe AI can fina...|[maybe, ai, can, ...|(27,[0,1,2,3,4,5,...|(27,[0,1,2,3,4,5,...|[0.0, 0.0, 0.5877...|\n",
      "|Maybe AI can fina...|[maybe, ai, can, ...|(27,[0,1,2,3,4,5,...|(27,[0,1,2,3,4,5,...|[0.0, 0.0, 0.5877...|\n",
      "|Maybe AI can fina...|[maybe, ai, can, ...|(27,[0,1,2,3,4,5,...|(27,[0,1,2,3,4,5,...|[0.0, 0.0, 0.5877...|\n",
      "|Maybe AI can fina...|[maybe, ai, can, ...|(27,[0,1,2,3,4,5,...|(27,[0,1,2,3,4,5,...|[0.0, 0.0, 0.5877...|\n",
      "|It is already my ...|[it, is, already,...|(27,[0,1,12,20,23...|(27,[0,1,12,20,23...|[0.0, 0.0, 0.0, 0...|\n",
      "|It is already my ...|[it, is, already,...|(27,[0,1,12,20,23...|(27,[0,1,12,20,23...|[0.0, 0.0, 0.0, 0...|\n",
      "|It is already my ...|[it, is, already,...|(27,[0,1,12,20,23...|(27,[0,1,12,20,23...|[0.0, 0.0, 0.0, 0...|\n",
      "|It is already my ...|[it, is, already,...|(27,[0,1,12,20,23...|(27,[0,1,12,20,23...|[0.0, 0.0, 0.0, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9c1a200-dede-4a1e-8f74-882a02c7c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = tfidf_df.select(explode(\n",
    "            array([struct(lit(vocab[i]).alias(\"word\"), col(\"tfidf_values\")[i].alias(\"tfidf\")) for i in range(len(vocab))])\n",
    "        ).alias(\"word_tfidf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f8b1fd2-6a4c-4508-a647-af3a0174c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:11:40 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          word_tfidf|\n",
      "+--------------------+\n",
      "|           {it, 0.0}|\n",
      "|           {is, 0.0}|\n",
      "|{supposed, 0.5877...|\n",
      "|{constantly, 0.58...|\n",
      "|{explain, 0.58778...|\n",
      "|{the, 0.587786664...|\n",
      "|{been, 0.58778666...|\n",
      "|{people, 0.587786...|\n",
      "|{since, 0.5877866...|\n",
      "|{mean,, 0.5877866...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05ff0707-d84d-47f3-aa7b-f6f129fc0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_df = exploded_df.select(\"word_tfidf.word\", \"word_tfidf.tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4984980-f68c-4367-b2cd-fc66a331e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = W.orderBy(col(\"tfidf\").desc())\n",
    "top_words_df = top_words_df.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce90fc1-16e0-4d60-8ada-644c80a65539",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_df = top_words_df.withColumn(\"window_start\", lit(window_start)).withColumn(\"window_end\", lit(window_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c3bcc34-181e-445e-bcef-5d4c316978e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:11:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/11 21:11:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/11 21:11:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 22:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----+-------------------+-------------------+\n",
      "|      word|             tfidf|rank|       window_start|         window_end|\n",
      "+----------+------------------+----+-------------------+-------------------+\n",
      "|    unable|0.5877866649021191|   1|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|     maybe|0.5877866649021191|   2|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|       far|0.5877866649021191|   3|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|  supposed|0.5877866649021191|   4|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|    “woke”|0.5877866649021191|   5|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|constantly|0.5877866649021191|   6|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|       can|0.5877866649021191|   7|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|       the|0.5877866649021191|   8|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|        to|0.5877866649021191|   9|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "|    people|0.5877866649021191|  10|2024-06-03 21:20:45|2024-06-03 21:21:45|\n",
      "+----------+------------------+----+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_words_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbc0c4-387e-4936-a991-d577cb5ba0f1",
   "metadata": {},
   "source": [
    "    def process_window(row):\n",
    "        window_start, window_end = row[\"window\"][\"start\"], row[\"window\"][\"end\"]\n",
    "        texts = row[\"texts\"]\n",
    "\n",
    "        # Create a DataFrame for the texts in the window\n",
    "        texts_df = spark.createDataFrame([(text,) for text in texts], [\"text\"])\n",
    "\n",
    "        # Fit the pipeline to the data\n",
    "        model = pipeline.fit(texts_df)\n",
    "\n",
    "        # Transform the data\n",
    "        tfidf_df = model.transform(texts_df)\n",
    "\n",
    "        # Extract the vocabulary and TF-IDF features\n",
    "        vocab = model.stages[1].vocabulary\n",
    "\n",
    "        # Convert sparse vector to dense vector\n",
    "        def to_array(v):\n",
    "            if v is None:\n",
    "                return None\n",
    "            return v.toArray().tolist()\n",
    "\n",
    "        to_array_udf = udf(to_array, ArrayType(DoubleType()))\n",
    "        tfidf_df = tfidf_df.withColumn(\"tfidf_values\", to_array_udf(col(\"features\")))\n",
    "\n",
    "        # Explode the features column to get individual words and their TF-IDF scores\n",
    "        exploded_df = tfidf_df.select(\n",
    "            explode(\n",
    "                array(\n",
    "                    [\n",
    "                        struct(\n",
    "                            lit(vocab[i]).alias(\"word\"),\n",
    "                            col(\"tfidf_values\")[i].alias(\"tfidf\"),\n",
    "                        )\n",
    "                        for i in range(len(vocab))\n",
    "                    ]\n",
    "                )\n",
    "            ).alias(\"word_tfidf\")\n",
    "        )\n",
    "\n",
    "        # Select word and tfidf score\n",
    "        top_words_df = exploded_df.select(\"word_tfidf.word\", \"word_tfidf.tfidf\")\n",
    "\n",
    "        # Get top 10 words based on TF-IDF scores\n",
    "        window_spec = W.orderBy(col(\"tfidf\").desc())\n",
    "        top_words_df = top_words_df.withColumn(\n",
    "            \"rank\", row_number().over(window_spec)\n",
    "        ).filter(col(\"rank\") <= 10)\n",
    "\n",
    "        # Add window information\n",
    "        top_words_df = top_words_df.withColumn(\n",
    "            \"window_start\", lit(window_start)\n",
    "        ).withColumn(\"window_end\", lit(window_end))\n",
    "\n",
    "        return top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576e078-80b0-40ba-9258-c2c4d2af6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_window(row):\n",
    "    window_start, window_end = row[\"window\"][\"start\"], row[\"window\"][\"end\"]\n",
    "    texts = row[\"texts\"]\n",
    "\n",
    "    # Create a DataFrame for the texts in the window\n",
    "    texts_df = spark.createDataFrame([(text,) for text in texts], [\"text\"])\n",
    "\n",
    "    # Fit the pipeline to the data\n",
    "    model = pipeline.fit(texts_df)\n",
    "\n",
    "    # Transform the data\n",
    "    tfidf_df = model.transform(texts_df)\n",
    "\n",
    "    # Extract the vocabulary and TF-IDF features\n",
    "    vocab = model.stages[1].vocabulary\n",
    "\n",
    "    # Convert sparse vector to dense vector\n",
    "    def to_array(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        return v.toArray().tolist()\n",
    "\n",
    "    to_array_udf = udf(to_array, ArrayType(DoubleType()))\n",
    "    tfidf_df = tfidf_df.withColumn(\"tfidf_values\", to_array_udf(col(\"features\")))\n",
    "\n",
    "    # Explode the features column to get individual words and their TF-IDF scores\n",
    "    exploded_df = tfidf_df.select(\n",
    "        explode(\n",
    "            array(\n",
    "                [\n",
    "                    struct(\n",
    "                        lit(vocab[i]).alias(\"word\"),\n",
    "                        col(\"tfidf_values\")[i].alias(\"tfidf\"),\n",
    "                    )\n",
    "                    for i in range(len(vocab))\n",
    "                ]\n",
    "            )\n",
    "        ).alias(\"word_tfidf\")\n",
    "    )\n",
    "\n",
    "    # Select word and tfidf score\n",
    "    top_words_df = exploded_df.select(\"word_tfidf.word\", \"word_tfidf.tfidf\")\n",
    "\n",
    "    # Get top 10 words based on TF-IDF scores\n",
    "    window_spec = W.orderBy(col(\"tfidf\").desc())\n",
    "    top_words_df = top_words_df.withColumn(\n",
    "        \"rank\", row_number().over(window_spec)\n",
    "    ).filter(col(\"rank\") <= 10)\n",
    "\n",
    "    # Add window information\n",
    "    top_words_df = top_words_df.withColumn(\n",
    "        \"window_start\", lit(window_start)\n",
    "    ).withColumn(\"window_end\", lit(window_end))\n",
    "\n",
    "    # Write the results to Parquet files\n",
    "    # partition_columns = [\"window_start\", \"window_end\"]\n",
    "    top_words_df.write.mode(\"append\").partitionBy(*partition_columns).parquet(output_dir)\n",
    "\n",
    "for row in windowed_df.rdd.collect():\n",
    "        process_window(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d7875-8f3a-4b3e-87f8-d1d0a2b1afc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d581a01-b7a5-4057-86e4-6582e66a0963",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bda8699-5c50-4096-a745-488208f81e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.read.parquet(\"data/tfidf/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ae3e04-de57-42dc-8b60-f085523a8f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+-------------------+-------------------+\n",
      "|    word|tfidf|rank|       window_start|         window_end|\n",
      "+--------+-----+----+-------------------+-------------------+\n",
      "|      ai|  0.0|   1|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|    take|  0.0|   2|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|  jobs….|  0.0|   3|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|creative|  0.0|   4|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|      ha|  0.0|   5|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|  menial|  0.0|   6|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|     ha.|  0.0|   7|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|    away|  0.0|   8|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|  mocked|  0.0|   9|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "|   years|  0.0|  10|2024-06-03 21:16:55|2024-06-03 21:17:55|\n",
      "| someone|  0.0|   1|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|      ha|  0.0|   2|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|      ai|  0.0|   3|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|  mocked|  0.0|   4|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|    take|  0.0|   5|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|artistic|  0.0|   6|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|   labor|  0.0|   7|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|     ha.|  0.0|   8|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|creative|  0.0|   9|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "|  jobs….|  0.0|  10|2024-06-03 21:17:10|2024-06-03 21:18:10|\n",
      "+--------+-----+----+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cb0d1-9d71-4319-b4d5-ea593f029cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
