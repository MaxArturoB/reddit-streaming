{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5c5191-6014-477c-bbc4-b1e72af73b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    array_join,\n",
    "    udf,\n",
    ")\n",
    "from sparknlp.base import DocumentAssembler\n",
    "\n",
    "from sparknlp.annotator import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sparknlp.annotator import (\n",
    "    StopWordsCleaner,\n",
    "    PerceptronModel,\n",
    "    Chunker,\n",
    "    LemmatizerModel,\n",
    "    Normalizer,\n",
    ")\n",
    "from sparknlp.base import Finisher\n",
    "from pyspark.ml import Pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e615a779-395b-4351-8781-c984168721be",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"data/raw/*.parquet\"\n",
    "output_dir=\"data/sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4903f999-0472-41b2-b802-7c5f9fbd3e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 18:44:37 WARN Utils: Your hostname, Exporo-MBP-219.local resolves to a loopback address: 127.0.0.1; using 10.10.5.83 instead (on interface en0)\n",
      "24/06/11 18:44:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/johnomole/anaconda3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/johnomole/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/johnomole/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "com.johnsnowlabs.nlp#spark-nlp-spark32_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-45065e8d-9e3b-408e-9ef3-99379a5b0815;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.7.0-M11 in central\n",
      "\tfound joda-time#joda-time;2.10.10 in central\n",
      "\tfound org.joda#joda-convert;2.2.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 1983ms :: artifacts dl 52ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.10 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.1 from central in [default]\n",
      "\torg.joda#joda-convert;2.2.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.21 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   30  |   0   |   0   |   1   ||   29  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-45065e8d-9e3b-408e-9ef3-99379a5b0815\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 29 already retrieved (0kB/34ms)\n",
      "24/06/11 18:44:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/11 18:44:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/06/11 18:44:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Reddit sentiment Processing\")\n",
    "    .master(\"local[*]\")  # Use local[*] master\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:3.4.2\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48c0532-6d60-46d3-9369-1a8456ada0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaccc72c-daf7-4914-ad9b-73f1d4f33e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "|     id|            author|  created_utc|score| parent_id|subreddit|           permalink|                text|          timestamp|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|\n",
      "|l6z1suj|     Sardoodledome|1.717450317E9|    1|t1_l6z1s7d| JoeRogan|/r/JoeRogan/comme...|\\n\\n# Research St...|2024-06-03 23:31:57|\n",
      "|l6z1suj|     Sardoodledome|1.717450317E9|    1|t1_l6z1s7d| JoeRogan|/r/JoeRogan/comme...|\\n\\n# Research St...|2024-06-03 23:31:57|\n",
      "|l6z1suj|     Sardoodledome|1.717450317E9|    1|t1_l6z1s7d| JoeRogan|/r/JoeRogan/comme...|\\n\\n# Research St...|2024-06-03 23:31:57|\n",
      "|l70bl6j|5chrodingers_pussy| 1.71746855E9|    3|t1_l6yvxy8| JoeRogan|/r/JoeRogan/comme...|This ^ \\n\\nWhat’s...|2024-06-04 04:35:50|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe66816c-313c-4440-9d84-72574bcf7eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 18:46:32 WARN BasicProfileConfigLoader: Your profile name includes a 'profile ' prefix. This is considered part of the profile name in the Java SDK, so you will need to include this prefix in your profile name when you reference this profile from your Java code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 907.6 KB\n",
      "[ / ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ — ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 18:47:37 WARN StopWordsCleaner: Default locale set was [en_PT]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[ | ]pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=35668Kb max_used=35674Kb free=95403Kb\n",
      " bounds [0x0000000106010000, 0x0000000108330000, 0x000000010e010000]\n",
      " total_blobs=13716 nmethods=12668 adapters=960\n",
      " compilation: disabled (not enough contiguous free space left)\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# prepare into spark format\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "# tokenisation\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"tokenized\")\n",
    "\n",
    "# convert the text to lowercase, empty string and special character\n",
    "normalizer = (\n",
    "    Normalizer()\n",
    "    .setInputCols([\"tokenized\"])\n",
    "    .setOutputCol(\"normalized\")\n",
    "    .setLowercase(True)\n",
    ")\n",
    "\n",
    "# lemmtizing tokens\n",
    "lemmatizer = (\n",
    "    LemmatizerModel.pretrained()\n",
    "    .setInputCols([\"normalized\"])\n",
    "    .setOutputCol(\"lemmatized\")\n",
    ")\n",
    "\n",
    "# remove stop words,\n",
    "eng_stopwords = stopwords.words(\"english\")\n",
    "stopwords_cleaner = (\n",
    "    StopWordsCleaner()\n",
    "    .setInputCols([\"lemmatized\"])\n",
    "    .setOutputCol(\"no_stop_lemmatized\")\n",
    "    .setStopWords(eng_stopwords)\n",
    ")\n",
    "\n",
    "pos_tagger = (\n",
    "    PerceptronModel.pretrained(\"pos_anc\")\n",
    "    .setInputCols([\"document\", \"lemmatized\"])\n",
    "    .setOutputCol(\"pos\")\n",
    ")\n",
    "\n",
    "allowed_tags = [\"<JJ>+<NN>\", \"<NN>+<NN>\"]\n",
    "chunker = (\n",
    "    Chunker()\n",
    "    .setInputCols([\"document\", \"pos\"])\n",
    "    .setOutputCol(\"ngrams\")\n",
    "    .setRegexParsers(allowed_tags)\n",
    ")\n",
    "finisher = Finisher().setInputCols(\n",
    "    [\"no_stop_lemmatized\", \"normalized\", \"tokenized\"]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline().setStages(\n",
    "    [\n",
    "        documentAssembler,\n",
    "        tokenizer,\n",
    "        normalizer,\n",
    "        lemmatizer,\n",
    "        stopwords_cleaner,\n",
    "        pos_tagger,\n",
    "        chunker,\n",
    "        finisher,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a034d8-8a8f-4964-910a-4f0f6d867b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pipeline.fit(df).transform(df)\n",
    "processed_df = processed_df.withColumn(\n",
    "        \"processed_text\", array_join(processed_df[\"finished_no_stop_lemmatized\"], \" \")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beaaf70e-e05a-4de6-aa9e-3d4d65227ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_schema = StructType(\n",
    "        [\n",
    "            StructField(\"compound\", DoubleType()),\n",
    "            StructField(\"positive\", DoubleType()),\n",
    "            StructField(\"neutral\", DoubleType()),\n",
    "            StructField(\"negative\", DoubleType()),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483bb76b-e878-44d5-873c-c68475413043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "        vs = analyzer.polarity_scores(text)\n",
    "        return (vs[\"compound\"], vs[\"pos\"], vs[\"neu\"], vs[\"neg\"])\n",
    "\n",
    "sentiment_udf = udf(get_sentiment, sentiment_schema)\n",
    "\n",
    "sentiment_df = processed_df.withColumn(\n",
    "    \"sentiment\", sentiment_udf(col(\"processed_text\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de23813b-baaa-40e0-87d8-cf855dd34bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment__df = (\n",
    "    sentiment_df.withColumn(\"compound\", col(\"sentiment.compound\"))\n",
    "    .withColumn(\"positive\", col(\"sentiment.positive\"))\n",
    "    .withColumn(\"neutral\", col(\"sentiment.neutral\"))\n",
    "    .withColumn(\"negative\", col(\"sentiment.negative\"))\n",
    "    .drop(\"sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e92689-fb3d-44a2-8118-349666d279e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "|     id|            author|  created_utc|score| parent_id|subreddit|           permalink|                text|          timestamp|finished_no_stop_lemmatized| finished_normalized|  finished_tokenized|      processed_text|compound|positive|neutral|negative|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|       [well, forget, ai...|[well, i, forgot,...|[Well, I, forgot,...|well forget ai ch...|  -0.607|   0.133|  0.703|   0.164|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|       [well, forget, ai...|[well, i, forgot,...|[Well, I, forgot,...|well forget ai ch...|  -0.607|   0.133|  0.703|   0.164|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment__df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7a5b43-4b51-4bae-98ee-8c72aea12a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 18:49:34 WARN DAGScheduler: Broadcasting large task binary with size 1200.7 KiB\n",
      "24/06/11 18:49:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "24/06/11 18:49:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "24/06/11 18:49:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment__df.write.mode(\"append\").parquet(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8179ae4-56af-4d5e-a786-fe9a649fa78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c7cf0-025d-4d83-92b9-efd063da1319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34626477-fda6-4bed-8eaf-e805261b1d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result = spark.read.parquet(\"data/sentiment/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b9ea021-8339-40c5-9991-345baff70a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "|     id|            author|  created_utc|score| parent_id|subreddit|           permalink|                text|          timestamp|finished_no_stop_lemmatized| finished_normalized|  finished_tokenized|      processed_text|compound|positive|neutral|negative|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l70kegt|5chrodingers_pussy|1.717472683E9|    2|t1_l70ii9i| JoeRogan|/r/JoeRogan/comme...|You bring up a co...|2024-06-04 05:44:43|       [bring, couple, s...|[you, bring, up, ...|[You, bring, up, ...|bring couple some...|  0.7305|   0.177|  0.679|   0.144|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|       [well, forget, ai...|[well, i, forgot,...|[Well, I, forgot,...|well forget ai ch...|  -0.607|   0.133|  0.703|   0.164|\n",
      "|l6z1s7d|     Sardoodledome|1.717450311E9|    1|t1_l6z1cw9| JoeRogan|/r/JoeRogan/comme...|Well I forgot abo...|2024-06-03 23:31:51|       [well, forget, ai...|[well, i, forgot,...|[Well, I, forgot,...|well forget ai ch...|  -0.607|   0.133|  0.703|   0.164|\n",
      "+-------+------------------+-------------+-----+----------+---------+--------------------+--------------------+-------------------+---------------------------+--------------------+--------------------+--------------------+--------+--------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3a71e4a-3d8f-466a-8461-218d679356fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:28:29 WARN TransportChannelHandler: Exception in connection from /10.10.5.83:64002\n",
      "java.io.IOException: Operation timed out\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:378)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    " 0.177 +  0.679 +   0.144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a30ec5-6a4b-496f-8269-0721394f5183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
